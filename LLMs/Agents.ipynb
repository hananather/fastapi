{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agents\n",
        "\n",
        "\n",
        "In this tutorial, we implement an AI agent from scratch in Python using an LLM API directly to gain a better understanding of what's happening under the hood.\n",
        "\n",
        "We implement the `Agent()` class step-by-step by incorporating the following core components: \n",
        "1. LLM (and instructions) : this is the LLM powering the agent's reasoning and decision-making capabilities with explicit guidelines of how the agent should behave.\n",
        "2. Memory: conversation history (short-term memory) and that agent uses to understand the current interaction.\n",
        "3. Tools: external tools that the agent can use to complete tasks.\n",
        "\n",
        "Component 1: LLM (and instructions)\n",
        "At the core of every agent, you have a large language model (LLM) with tool use capabilities.\n",
        "\n",
        "We will use Claude for Sonnet through the Anthropic API, but we can easily adjust the code to any other LLM API of our choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U anthropic python-dotenv\n",
        "\n",
        "import anthropic\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "print(anthropic.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncPage[ModelInfo](data=[ModelInfo(id='claude-haiku-4-5-20251001', created_at=datetime.datetime(2025, 10, 15, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude Haiku 4.5', type='model'), ModelInfo(id='claude-sonnet-4-5-20250929', created_at=datetime.datetime(2025, 9, 29, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude Sonnet 4.5', type='model'), ModelInfo(id='claude-opus-4-1-20250805', created_at=datetime.datetime(2025, 8, 5, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude Opus 4.1', type='model'), ModelInfo(id='claude-opus-4-20250514', created_at=datetime.datetime(2025, 5, 22, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude Opus 4', type='model'), ModelInfo(id='claude-sonnet-4-20250514', created_at=datetime.datetime(2025, 5, 22, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude Sonnet 4', type='model'), ModelInfo(id='claude-3-7-sonnet-20250219', created_at=datetime.datetime(2025, 2, 24, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude Sonnet 3.7', type='model'), ModelInfo(id='claude-3-5-haiku-20241022', created_at=datetime.datetime(2024, 10, 22, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude Haiku 3.5', type='model'), ModelInfo(id='claude-3-haiku-20240307', created_at=datetime.datetime(2024, 3, 7, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude Haiku 3', type='model'), ModelInfo(id='claude-3-opus-20240229', created_at=datetime.datetime(2024, 2, 29, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude Opus 3', type='model')], has_more=False, first_id='claude-haiku-4-5-20251001', last_id='claude-3-opus-20240229')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
        "client.models.list()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    \"A simple Agent that can answer questions\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
        "        self.model = 'claude-haiku-4-5-20251001'\n",
        "        self.system_message = \"You are a helpful assistant that breaks down problems into steps and solves them systematically.\"\n",
        "\n",
        "    def chat(self, message):\n",
        "        \"Process user message and return response\"\n",
        "        \n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=1024,\n",
        "            system=self.system_message,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": message}\n",
        "                ],\n",
        "            temperature=0.1,\n",
        "        )\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't have any apples! I'm an AI assistant, so I don't possess physical objects.\n",
            "\n",
            "But I can help you with questions about your apples, like:\n",
            "- How many you'd have if you got more or gave some away\n",
            "- How to divide them among people\n",
            "- Recipes or storage tips\n",
            "- Math problems involving them\n",
            "\n",
            "Is there something specific you'd like to do with your 4 apples?\n"
          ]
        }
      ],
      "source": [
        "agent = Agent()\n",
        "response = agent.chat(\"I have 4 apples. How many do you have?\")\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's follow it up with a second message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't have enough information to answer this question. To tell you how many apples are left, I would need to know:\n",
            "\n",
            "**How many apples did you start with?**\n",
            "\n",
            "For example:\n",
            "- If you started with 5 apples and ate 1, you'd have **4 left**\n",
            "- If you started with 10 apples and ate 1, you'd have **9 left**\n",
            "\n",
            "Could you tell me the starting number of apples?\n"
          ]
        }
      ],
      "source": [
        "agent = Agent()\n",
        "response = agent.chat(\"I ate one apple. How many are left ?\")\n",
        "print(response.content[0].text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the agent lacks the information from the first message. That’s why we need to give the agent access to the conversation history.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Component 2: (Conversation) Memory\n",
        "Memory in Agents can take many forms, such as short-term and long-term memory, and memory management can become a complex topic. For the sake of this tutorial, let's just keep it simple and start with a basic short-term memory implementation.\n",
        "\n",
        "Short-term memory gives the agent access to the conversation state to the conversation history to understand the current interaction. In its simplest form, the short-term memory is just a list of past `messages` between the `user` and the `assistant` (note that the longer the conversaton becomes, you will run into the context window limitations and need to implement a more sophisticated solution).\n",
        "We implement a short-term memory by adding `messages` property where we store\n",
        "- the user input with `{\"role\": \"user\", \"content\": message}`\n",
        "- the response with `{\"role\": \"assistant\", \"content\": response}`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    \"A simple Agent that can answer questions\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
        "        self.model = 'claude-haiku-4-5-20251001'\n",
        "        self.system_message = \"You are a helpful assistant that breaks down problems into steps and solves them systematically.\"\n",
        "        self.messages = []\n",
        "\n",
        "\n",
        "    def chat(self, message):\n",
        "        \"Process user message and return response\"\n",
        "        # Store user input in short-term memory\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "        \n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=1024,\n",
        "            system=self.system_message,\n",
        "            messages=self.messages,\n",
        "            temperature=0.1,\n",
        "        )\n",
        "        # Store assistant's response in short-term memory\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I don't have any apples! I'm an AI assistant, so I don't possess physical objects.\n",
            "\n",
            "But I can help you with questions about your apples, like:\n",
            "- How many you'd have if you got more or gave some away\n",
            "- How to divide them among people\n",
            "- Recipes or storage tips\n",
            "- Math problems involving them\n",
            "\n",
            "Is there something specific you'd like to do with your 4 apples?\n",
            "You started with 4 apples and ate 1, so:\n",
            "\n",
            "4 - 1 = **3 apples left**\n"
          ]
        }
      ],
      "source": [
        "agent = Agent()\n",
        "\n",
        "response = agent.chat(\"I have 4 apples. How many do you have?\")\n",
        "print(response.content[0].text)\n",
        "\n",
        "response = agent.chat(\"I ate 1 apple. How many are left?\")\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the agent is now able to hold a conversation and to reference previous information.\n",
        "\n",
        "But what happens, if you task the agent with a little more complex math problem?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'll multiply 157.09 × 493.89 step by step.\n",
            "\n",
            "**Breaking it down:**\n",
            "\n",
            "157.09 × 493.89\n",
            "\n",
            "Let me calculate this:\n",
            "\n",
            "157.09 × 493.89 = **77,516.0301**\n",
            "\n",
            "**Verification using the standard algorithm:**\n",
            "- 157.09 has 2 decimal places\n",
            "- 493.89 has 2 decimal places\n",
            "- Total decimal places in answer: 4\n",
            "\n",
            "157.09 × 493.89 ≈ **77,516.03** (rounded to 2 decimal places)\n",
            "\n",
            "The answer is **77,516.0301** or approximately **77,516.03**\n"
          ]
        }
      ],
      "source": [
        "agent = Agent()\n",
        "\n",
        "response = agent.chat(\"What is 157.09 * 493.89?\")\n",
        "\n",
        "print(response.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The agent’s answer sounds perfectly believable but if you validate it, you can actually see that even powerful LLMs like Claude 4 Sonnet can still make arithmetic errors without tools.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77585.1801"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "157.09 * 493.89\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Component 3: Tool Use\n",
        "To extend the agent's capabilities, we can provide it with tools that can range from simple functions to using external APIs. For this tutorial, we'll implement a simple `CalculatorTool` class that can handle math problems.\n",
        "\n",
        "The exact implementation of tool use is different across providers, but at the core, always requires two key components:\n",
        "- Function implementation: which is the actual function that executes the tool's logic, such as performing a calculation or making an API call.\n",
        "- Tool schema: a structured description of the tool. The tool description is important because it tells the LLM what this tool does, when to use it, and what parameters it takes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CalculatorTool():\n",
        "    \"\"\"A tool for performing mathematical calculations\"\"\"\n",
        "\n",
        "    def get_schema(self):\n",
        "        return {\n",
        "            \"name\": \"calculator\",\n",
        "            \"description\": \"Performs basic mathematical calculations, use also for simple additions\",\n",
        "            \"input_schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"expression\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Mathematical expression to evaluate (e.g., '2+2', '10*5')\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"expression\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def execute(self, expression):\n",
        "        \"\"\"\n",
        "        Evaluate mathematical expressions.\n",
        "        WARNING: This tutorial uses eval() for simplicity but it is not recommended for production use.\n",
        "\n",
        "        Args:\n",
        "            expression (str): The mathematical expression to evaluate\n",
        "        Returns:\n",
        "            float: The result of the evaluation\n",
        "        \"\"\"\n",
        "        try:\n",
        "            result = eval(expression)\n",
        "            return {\"result\": result}\n",
        "        except:\n",
        "            return {\"error\": \"Invalid mathematical expression\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we are just implementing a single tool. In production code, you typically use an abstract base class to ensure a consistent interface across the tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': 77585.1801}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calculator_tool = CalculatorTool()\n",
        "\n",
        "calculator_tool.execute(\"157.09 * 493.89\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have a `CalculatorTool`, let's add tool use capabilities to our agent in the next three steps.\n",
        "1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from anthropic import Anthropic\n",
        "class Agent:\n",
        "    \"A simple Agent that can answer questions\"\n",
        "\n",
        "    def __init__(self, tools):\n",
        "        self.client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
        "        self.model = 'claude-haiku-4-5-20251001'\n",
        "        self.system_message = \"You are a helpful assistant that breaks down problems into steps and solves them systematically.\"\n",
        "        self.messages = []\n",
        "        self.tools = tools\n",
        "        self.tool_map = {tool.get_schema()[\"name\"]: tool for tool in tools}\n",
        "\n",
        "\n",
        "    def _get_tool_schemas(self):\n",
        "        \"\"\"Get the tool schema from the tools\"\"\"\n",
        "        return [tool.get_schema() for tool in self.tools]\n",
        "\n",
        "    def chat(self, message):\n",
        "        \"Process user message and return response\"\n",
        "        # Store user input in short-term memory\n",
        "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
        "        \n",
        "        response = self.client.messages.create(\n",
        "            model=self.model,\n",
        "            max_tokens=1024,\n",
        "            system=self.system_message,\n",
        "            tools=self._get_tool_schemas() if self.tools else None,\n",
        "            messages=self.messages,\n",
        "            temperature=0.1,\n",
        "        )\n",
        "        # Store assistant's response in short-term memory\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('id', 'msg_01XNG4K8cWnP9ALUs6Q7imKG')\n",
            "('content', [ToolUseBlock(id='toolu_01RjtcyeLSVEFJASHUN6snB2', input={'expression': '157.09 * 493.89'}, name='calculator', type='tool_use')])\n",
            "('model', 'claude-haiku-4-5-20251001')\n",
            "('role', 'assistant')\n",
            "('stop_reason', 'tool_use')\n",
            "('stop_sequence', None)\n",
            "('type', 'message')\n",
            "('usage', Usage(cache_creation=CacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=616, output_tokens=60, server_tool_use=None, service_tier='standard'))\n"
          ]
        }
      ],
      "source": [
        "calculator_tool = CalculatorTool()\n",
        "agent = Agent(tools=[calculator_tool])\n",
        "\n",
        "response = agent.chat(\"What is 157.09 * 493.89?\")\n",
        "\n",
        "for block in response:\n",
        "  print(block)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def run_agent(user_input, max_turns=10):\n",
        "  calculator_tool = CalculatorTool()\n",
        "  agent = Agent(tools=[calculator_tool])\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  while i < max_turns: # It's safer to use max_turns rather than while True\n",
        "    i += 1\n",
        "    print(f\"\\nIteration {i}:\")\n",
        "\n",
        "    print(f\"User input: {user_input}\")\n",
        "    response = agent.chat(user_input)\n",
        "    print(f\"Agent output: {response.content[0].text}\")\n",
        "\n",
        "    # Handle tool use if present\n",
        "    if response.stop_reason == \"tool_use\":\n",
        "\n",
        "        # Process all tool uses in the response\n",
        "        tool_results = []\n",
        "        for content_block in response.content:\n",
        "            if content_block.type == \"tool_use\":\n",
        "                tool_name = content_block.name\n",
        "                tool_input = content_block.input\n",
        "\n",
        "                print(f\"Using tool {tool_name} with input {tool_input}\")\n",
        "\n",
        "                # Execute the tool\n",
        "                tool = agent.tool_map[tool_name]\n",
        "                tool_result = tool.execute(**tool_input)\n",
        "\n",
        "                tool_results.append({\n",
        "                    \"type\": \"tool_result\",\n",
        "                    \"tool_use_id\": content_block.id,\n",
        "                    \"content\": json.dumps(tool_result)\n",
        "                })\n",
        "                print(f\"Tool result: {tool_result}\")\n",
        "\n",
        "        # Add tool results to conversation\n",
        "        user_input = tool_results\n",
        "    else:\n",
        "      return response.content[0].text\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1:\n",
            "User input: If my brother is 32 years younger than my mother and my mother is 30 years older than me and I am 20, how old is my brother?\n",
            "Agent output: I need to work through this step-by-step.\n",
            "\n",
            "Given information:\n",
            "- I am 20 years old\n",
            "- My mother is 30 years older than me\n",
            "- My brother is 32 years younger than my mother\n",
            "\n",
            "Let me calculate:\n",
            "Using tool calculator with input {'expression': '20 + 30'}\n",
            "Tool result: {'result': 50}\n",
            "Using tool calculator with input {'expression': '50 - 32'}\n",
            "Tool result: {'result': 18}\n",
            "\n",
            "Iteration 2:\n",
            "User input: [{'type': 'tool_result', 'tool_use_id': 'toolu_01FZhbohdMxtnwuTt6c918ST', 'content': '{\"result\": 50}'}, {'type': 'tool_result', 'tool_use_id': 'toolu_01DdYbdUjS29hWYheXPaVuGp', 'content': '{\"result\": 18}'}]\n",
            "Agent output: **Your brother is 18 years old.**\n",
            "\n",
            "Here's the breakdown:\n",
            "1. You are 20 years old\n",
            "2. Your mother is 30 years older than you: 20 + 30 = **50 years old**\n",
            "3. Your brother is 32 years younger than your mother: 50 - 32 = **18 years old**\n"
          ]
        }
      ],
      "source": [
        "response = run_agent(\"If my brother is 32 years younger than my mother and my mother is 30 years older than me and I am 20, how old is my brother?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
